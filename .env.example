# --- LLM Configuration ---
# Primary provider (openai, anthropic, ollama, groq, together)
KATALYST_LLM_PROVIDER=openai

# Option 1: Use pre-configured provider profiles (recommended for easy switching)
# KATALYST_LLM_PROFILE=anthropic  # Uses Claude models with sensible defaults
# KATALYST_LLM_PROFILE=ollama     # Uses local Ollama models
# KATALYST_LLM_PROFILE=groq       # Uses Groq/Llama models with sensible defaults

# Option 2: Manually specify models (advanced users)
# Use a powerful model for planning and replanning (high-reasoning tasks)
KATALYST_REASONING_MODEL="gpt-4.1"

# Use a faster, cheaper model for execution and tool use (low-reasoning tasks)
KATALYST_EXECUTION_MODEL="gpt-4.1"

# Fallback model if primary model fails
KATALYST_LLM_MODEL_FALLBACK="gpt-4o"

# Default timeout for all LLM calls
KATALYST_LLM_TIMEOUT=45

# --- Agent Behavior ---
KATALYST_AUTO_APPROVE=False
# KATALYST_MAX_INNER_REACT_CYCLES=20  # Not used - create_react_agent handles its own loop
KATALYST_MAX_OUTER_PLANNER_CYCLES=10
KATALYST_RECURSION_LIMIT=250

# --- Debugging ---
# Enable verbose reasoning to see agent's thought process in logs
KATALYST_VERBOSE_REASONING=True

# --- MINIMAL: The following are not used in minimal implementation ---
# # --- Chat History Management ---
# # Trigger chat summarization when history exceeds this many messages
# KATALYST_CHAT_SUMMARY_TRIGGER=50
# # Number of recent messages to keep after summarization
# KATALYST_CHAT_SUMMARY_KEEP_LAST_N=10

# # --- Context Tracking ---
# # Number of recent file operations to track
# KATALYST_FILE_CONTEXT_HISTORY=10
# # Number of recent tool operations to track
# KATALYST_OPERATIONS_CONTEXT_HISTORY=10

# # --- Action Trace (Scratchpad) Management ---
# # Trigger action trace summarization after this many actions
# KATALYST_ACTION_TRACE_TRIGGER=10
# # Number of recent actions to keep after summarization
# KATALYST_ACTION_TRACE_KEEP_LAST_N=5

# --- API Keys ---
# OpenAI API key (required for OpenAI provider)
OPENAI_API_KEY=

# Anthropic API key (required for Anthropic provider)
# ANTHROPIC_API_KEY=

# Groq API key (required for Groq provider)
# GROQ_API_KEY=

# Together API key (required for Together provider)
# TOGETHER_API_KEY=

# Note: Ollama runs locally and doesn't require an API key